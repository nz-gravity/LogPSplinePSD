{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cca3f3aa3659899",
   "metadata": {
    "id": "4cca3f3aa3659899"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/nz-gravity/LogPSplinePSD/tree/main/docs/studies/lvk/lvk_demo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    " # LVK Demo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78a5ab4bc01fb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e78a5ab4bc01fb0",
    "outputId": "fe3a4d2f-dbba-46e8-b899-fc388fc73a96"
   },
   "outputs": [],
   "source": [
    "! pip install logPsplinePSD[gw] -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e02f737691eddb07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T02:25:45.662375Z",
     "start_time": "2025-09-11T02:25:45.281117Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "e02f737691eddb07",
    "outputId": "881ff9d9-5b0c-4618-c3ec-f567763b9265",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c105b713b89db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T03:29:59.151606Z",
     "start_time": "2025-09-11T03:29:58.596512Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "e86c105b713b89db",
    "outputId": "92f96e4b-e96b-40ed-9d36-5d15a340655b",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from log_psplines.datatypes import Periodogram, Timeseries\n",
    "\n",
    "FMIN, FMAX = 15, 1024\n",
    "\n",
    "\n",
    "URL = \"https://raw.githubusercontent.com/bilby-dev/bilby/main/bilby/gw/detector/noise_curves/aLIGO_O4_high_asd.txt\"\n",
    "\n",
    "\n",
    "def load_lvk_psd() -> Periodogram:\n",
    "    df = pd.read_csv(URL, comment=\"#\", sep=\"\\s+\", header=None)\n",
    "    freq, asd = df[0].values, df[1].values\n",
    "    return Periodogram(freq, asd**2)\n",
    "\n",
    "\n",
    "def create_white_noise(sampling_frequency: float, duration: float):\n",
    "    number_of_samples = duration * sampling_frequency\n",
    "    number_of_samples = int(np.round(number_of_samples))\n",
    "\n",
    "    number_of_samples = int(np.round(duration * sampling_frequency))\n",
    "    number_of_frequencies = int(np.round(number_of_samples / 2) + 1)\n",
    "\n",
    "    frequencies = np.linspace(\n",
    "        start=0, stop=sampling_frequency / 2, num=number_of_frequencies\n",
    "    )\n",
    "    norm1 = 0.5 * duration**0.5\n",
    "    re1, im1 = np.random.normal(0, norm1, (2, len(frequencies)))\n",
    "    white_noise = re1 + 1j * im1\n",
    "\n",
    "    # set DC and Nyquist = 0\n",
    "    white_noise[0] = 0\n",
    "    # no Nyquist frequency when N=odd\n",
    "    if np.mod(number_of_samples, 2) == 0:\n",
    "        white_noise[-1] = 0\n",
    "\n",
    "    # python: transpose for use with infft\n",
    "    white_noise = np.transpose(white_noise)\n",
    "    frequencies = np.transpose(frequencies)\n",
    "    return white_noise, frequencies\n",
    "\n",
    "\n",
    "def get_lvk_noise_realisation(sampling_frequency=4096.0, duration=32.0):\n",
    "    psd = load_lvk_psd()\n",
    "    white_noise, frequencies = create_white_noise(sampling_frequency, duration)\n",
    "\n",
    "    with np.errstate(invalid=\"ignore\"):\n",
    "        colored_noise = (\n",
    "            np.interp(frequencies, psd.freqs, psd.power) ** 0.5 * white_noise\n",
    "        )\n",
    "\n",
    "    n_samples = int(sampling_frequency * duration)\n",
    "    colored_noise_time = np.fft.irfft(colored_noise, n=n_samples)\n",
    "    times = np.arange(n_samples) / sampling_frequency\n",
    "    ts = Timeseries(times, colored_noise_time)\n",
    "\n",
    "    # Compute periodogram from the time series\n",
    "    freqs = np.fft.rfftfreq(n_samples, 1 / sampling_frequency)\n",
    "    fft_data = np.fft.rfft(colored_noise_time)\n",
    "    pdgrm_power = np.abs(fft_data) ** 2\n",
    "    pdgrm = Periodogram(freqs[1:-1], pdgrm_power[1:-1])\n",
    "    return ts, pdgrm\n",
    "\n",
    "\n",
    "lvk_psd = load_lvk_psd()\n",
    "lvk_noise, lvk_pdgrm = get_lvk_noise_realisation()\n",
    "\n",
    "\n",
    "plt.plot(\n",
    "    lvk_pdgrm.freqs,\n",
    "    (lvk_pdgrm.power),\n",
    "    label=\"LVK noise realisation\",\n",
    "    color=\"gray\",\n",
    "    alpha=0.5,\n",
    "    lw=2,\n",
    ")\n",
    "plt.loglog(lvk_psd.freqs, lvk_psd.power, \"k-\", label=\"aLIGO O4 design\", lw=1)\n",
    "plt.xlim(FMIN, FMAX)\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.ylabel(\"PSD [1/Hz]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ee0f3bee1efdb4",
   "metadata": {
    "id": "c8ee0f3bee1efdb4"
   },
   "source": [
    "## Knot allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b151621650f4f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T04:41:14.263501Z",
     "start_time": "2025-09-11T04:41:14.240168Z"
    },
    "id": "b151621650f4f8e"
   },
   "outputs": [],
   "source": [
    "# knot allocation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "def extract_peaks(vec, window=9, threshold_factor=1.0):\n",
    "    \"\"\"\n",
    "    vec: array-like, the periodogram in original scale\n",
    "    returns: array with log-peaks, otherwise 0\n",
    "    \"\"\"\n",
    "    vec = np.asarray(vec)\n",
    "    n = len(vec)\n",
    "\n",
    "    # Rolling median (window size 9, centered)\n",
    "    med_psd = (\n",
    "        pd.Series(vec)\n",
    "        .rolling(window=window, center=True, min_periods=1)\n",
    "        .median()\n",
    "        .to_numpy()\n",
    "    )\n",
    "\n",
    "    # Power ratio\n",
    "    ratio_med = vec / (med_psd + np.finfo(float).eps)\n",
    "    log_ratio_med = np.log(ratio_med)\n",
    "\n",
    "    # Replace NaNs with mean\n",
    "    mean_lr = np.nanmean(log_ratio_med)\n",
    "    log_ratio_med = np.where(np.isnan(log_ratio_med), mean_lr, log_ratio_med)\n",
    "\n",
    "    # Threshold = Q3 + 1.5 * (Q3 - Q1)\n",
    "    Q1 = np.nanquantile(log_ratio_med, 0.25)\n",
    "    Q3 = np.nanquantile(log_ratio_med, 0.75)\n",
    "    threshold = (Q3 + 1.5 * (Q3 - Q1)) * threshold_factor\n",
    "\n",
    "    # Find values greater than threshold\n",
    "    out = np.zeros(n)\n",
    "    out[log_ratio_med > threshold] = log_ratio_med[log_ratio_med > threshold]\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "from scipy.signal.windows import gaussian\n",
    "\n",
    "\n",
    "def smooth_peaks(vec, d):\n",
    "    \"\"\"\n",
    "    Returns the smoothed vector with peaks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vec : array-like, Vector with peaks.\n",
    "    d : int, Propagation distance to the left and right.\n",
    "    \"\"\"\n",
    "    vec = np.asarray(vec)\n",
    "    out = vec.copy()\n",
    "    n = len(vec)\n",
    "\n",
    "    # Gaussian decay (like gsignal::gausswin in R)\n",
    "    gauss_win = gaussian(2 * d, std=2.5)\n",
    "    dec = gauss_win[:d][::-1]  # take first d and reverse\n",
    "\n",
    "    for i in range(1, d + 1):\n",
    "        # propagate to the left\n",
    "        aux1 = np.concatenate([vec[i:], np.zeros(i)])\n",
    "        # propagate to the right\n",
    "        aux2 = np.concatenate([np.zeros(i), vec[: n - i]])\n",
    "\n",
    "        # apply Gaussian decay\n",
    "        aux1 = aux1 * dec[i - 1]\n",
    "        aux2 = aux2 * dec[i - 1]\n",
    "\n",
    "        # update with maximum\n",
    "        out = np.maximum(out, aux1)\n",
    "        out = np.maximum(out, aux2)\n",
    "\n",
    "    # Areas between peaks: aassign\n",
    "    m0 = np.sum(out) * 0.05  # 5 percent of total peaks\n",
    "    n0 = np.count_nonzero(out)  # number of non-zeros\n",
    "    if n0 > 0:\n",
    "        min_value = m0 / n0\n",
    "        out[out <= min_value] = min_value\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def knotLoc(vec, k, degree, eqSpaced=False):\n",
    "    \"\"\"\n",
    "    Compute knot locations for B-spline densities.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vec : array-like, Numeric vector containing the smoothed peaks.\n",
    "    k : int,  Number of B-spline densities.\n",
    "    degree : int\n",
    "        Degree of the B-spline densities.\n",
    "    eqSpaced : bool, optional (default=False)\n",
    "        If True, returns equidistant knots in [0,1].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    knots : ndarray\n",
    "        Knot positions in [0,1].\n",
    "    \"\"\"\n",
    "    K = k - degree + 1  # number of internal knots in [0,1]\n",
    "    vec = np.asarray(vec)\n",
    "\n",
    "    if eqSpaced:\n",
    "        knots = np.linspace(0, 1, K)\n",
    "        return knots\n",
    "\n",
    "    N = len(vec)\n",
    "\n",
    "    # Normalized density\n",
    "    dens = vec / np.sum(vec)\n",
    "    cumf = np.cumsum(dens)\n",
    "\n",
    "    # Distribution function (maps [0,1] -> [0,1])\n",
    "    df = interp1d(\n",
    "        np.linspace(0, 1, N),\n",
    "        cumf,\n",
    "        kind=\"linear\",\n",
    "        bounds_error=False,\n",
    "        fill_value=(0, 1),\n",
    "    )\n",
    "\n",
    "    # Inverse distribution function\n",
    "    grid = np.linspace(0, 1, N)\n",
    "    dfvec = df(grid)\n",
    "    invDf = interp1d(\n",
    "        dfvec, grid, kind=\"linear\", bounds_error=False, fill_value=np.nan\n",
    "    )\n",
    "\n",
    "    # Internal points (exclude 0 and 1)\n",
    "    v = np.linspace(0, 1, K)\n",
    "    v = v[1:-1]\n",
    "\n",
    "    knots = np.concatenate(([0], invDf(v), [1]))\n",
    "\n",
    "    return knots\n",
    "\n",
    "\n",
    "def peak_and_knot_loc(pdgrm):\n",
    "    # 1. Identifying peaks\n",
    "    aux = extract_peaks(pdgrm.power, window=9, threshold_factor=1.0)\n",
    "\n",
    "    # 2. Smoothed peaks\n",
    "    r = smooth_peaks(aux, 40)\n",
    "\n",
    "    # 3. Compute knots\n",
    "    k = knotLoc(vec=r, k=100, degree=3)\n",
    "    maxFreq = np.max(pdgrm.freqs)  # Maximum frequency\n",
    "    return r, k * maxFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f39c3693834ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T03:29:59.939985Z",
     "start_time": "2025-09-11T03:29:59.763293Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "c96f39c3693834ab",
    "outputId": "a62b4b3e-acc9-4ad0-8037-1e1a47d25e70"
   },
   "outputs": [],
   "source": [
    "lvk_std = np.std(lvk_noise.y)\n",
    "noise_standardised = (lvk_noise.y - np.mean(lvk_noise.y)) / lvk_std\n",
    "freqs = np.fft.rfftfreq(lvk_noise.n, 1 / lvk_noise.fs)\n",
    "pdgrm = Periodogram(\n",
    "    freqs=freqs, power=np.abs(np.fft.rfft(noise_standardised)) ** 2\n",
    ")\n",
    "pdgrm = pdgrm.cut(FMIN, FMAX)\n",
    "plt.loglog(pdgrm.freqs, pdgrm.power, color=\"gray\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63b6dfdc00780ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T03:30:50.510414Z",
     "start_time": "2025-09-11T03:30:50.134066Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "a63b6dfdc00780ab",
    "outputId": "2d3d5bfa-d9e5-4e52-a485-51e94e5a9ff2"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# 1. Identifying peaks\n",
    "aux = extract_peaks(pdgrm.power, window=9, threshold_factor=1.0)\n",
    "\n",
    "# 2. Smoothed peaks\n",
    "r = smooth_peaks(aux, 40)\n",
    "\n",
    "# 3. Plot identified peaks\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(pdgrm.freqs, aux, linestyle=\"-\", color=\"blue\")\n",
    "plt.title(\"Identified Peaks\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"log Peaks\")\n",
    "plt.show()\n",
    "\n",
    "# 4. Plot areas to allocate knots (smoothed peaks)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(pdgrm.freqs, r, linestyle=\"-\", color=\"red\")\n",
    "plt.title(\"Smoothed peaks\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Smoothed Peaks\")\n",
    "plt.show()\n",
    "\n",
    "#####################\n",
    "### Ploting Knots ###\n",
    "#####################\n",
    "\n",
    "# 1. Compute knots\n",
    "k = knotLoc(vec=r, k=100, degree=3)\n",
    "maxFreq = np.max(pdgrm.freqs)  # Maximum frequency\n",
    "\n",
    "# 2. Plot LVK periodogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(pdgrm.freqs, np.log(pdgrm.power), linestyle=\"-\", color=\"lightgray\")\n",
    "plt.title(\"LVK Periodogram\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Log-periodogram\")\n",
    "\n",
    "# Red points: knot locations\n",
    "plt.scatter(k * maxFreq, np.full_like(k, -35), color=\"red\", label=\"Knots\")\n",
    "\n",
    "# 3. Distribution function from smoothed peaks\n",
    "N = len(r)\n",
    "dens = r / np.sum(r)\n",
    "cumf = np.cumsum(dens)\n",
    "\n",
    "# Interpolation function (distribution function)\n",
    "df = interp1d(\n",
    "    np.linspace(0, 1, N),\n",
    "    cumf,\n",
    "    kind=\"linear\",\n",
    "    bounds_error=False,\n",
    "    fill_value=(0, 1),\n",
    ")\n",
    "\n",
    "# 4. Plot areas to allocate knots\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(\n",
    "    pdgrm.freqs,\n",
    "    r / np.max(r),\n",
    "    linestyle=\"-\",\n",
    "    color=\"lightgray\",\n",
    "    label=\"Normalized Smoothed Peaks\",\n",
    ")\n",
    "\n",
    "# Add cumulative distribution (red line)\n",
    "plt.plot(\n",
    "    pdgrm.freqs,\n",
    "    df(np.array(pdgrm.freqs) / 2048),\n",
    "    color=\"red\",\n",
    "    label=\"CDF\",\n",
    ")\n",
    "\n",
    "plt.title(\"Smoothed peaks & CDF\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Normalized Peaks / CDF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f0c8f31414128a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T03:49:36.695642Z",
     "start_time": "2025-09-11T03:48:34.327121Z"
    },
    "id": "50f0c8f31414128a"
   },
   "outputs": [],
   "source": [
    "from log_psplines.mcmc import run_mcmc\n",
    "\n",
    "# Run MCMC\n",
    "mcmc_results = run_mcmc(\n",
    "    pdgrm,\n",
    "    n_warmup=1000,\n",
    "    n_samples=2000,\n",
    "    knot_kwargs=dict(knots=k * maxFreq, degree=3),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137e5499773ea678",
   "metadata": {
    "id": "137e5499773ea678"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80e0814a6bb5968",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T04:19:14.479974Z",
     "start_time": "2025-09-11T04:19:12.158525Z"
    },
    "id": "f80e0814a6bb5968"
   },
   "outputs": [],
   "source": [
    "from log_psplines.plotting import plot_pdgrm\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "fig = plot_pdgrm(idata=mcmc_results, interactive=True)\n",
    "\n",
    "display(HTML(fig.to_html(include_plotlyjs=\"cdn\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f00a619ba79f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T04:04:51.091845Z",
     "start_time": "2025-09-11T04:02:44.278833Z"
    },
    "id": "cd8f00a619ba79f4"
   },
   "outputs": [],
   "source": [
    "# This is the current saved LVK knot allocation method in logPsplinePSD\n",
    "mcmc_results_v2 = run_mcmc(\n",
    "    pdgrm,\n",
    "    n_warmup=1000,\n",
    "    n_samples=2000,\n",
    "    knot_kwargs=dict(degree=3, method=\"lvk\"),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61879a8572308f5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T04:19:24.443430Z",
     "start_time": "2025-09-11T04:19:22.157664Z"
    },
    "id": "61879a8572308f5a"
   },
   "outputs": [],
   "source": [
    "from log_psplines.plotting import plot_pdgrm\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "fig = plot_pdgrm(idata=mcmc_results_v2, interactive=True)\n",
    "display(HTML(fig.to_html(include_plotlyjs=\"cdn\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761d2788e9493b6d",
   "metadata": {
    "id": "761d2788e9493b6d"
   },
   "source": [
    "## GW1500914\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d520fb8b29313b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T04:42:16.803698Z",
     "start_time": "2025-09-11T04:42:15.138506Z"
    },
    "id": "63d520fb8b29313b"
   },
   "outputs": [],
   "source": [
    "from log_psplines.example_datasets.lvk_data import LVKData\n",
    "\n",
    "data = LVKData.from_event(\"GW150914\")\n",
    "data.plot_psd()\n",
    "pdgrm = Periodogram(data.freqs, data.psd)\n",
    "pdgrm = pdgrm.cut(20, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903e0ca97fa31e8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T04:43:05.256868Z",
     "start_time": "2025-09-11T04:42:50.655215Z"
    },
    "id": "903e0ca97fa31e8a"
   },
   "outputs": [],
   "source": [
    "r, k = peak_and_knot_loc(pdgrm)\n",
    "gw150914_psd_patricio = run_mcmc(\n",
    "    pdgrm,\n",
    "    n_warmup=1000,\n",
    "    n_samples=2000,\n",
    "    knot_kwargs=dict(degree=3, knots=k),\n",
    "    verbose=True,\n",
    "    sampler=\"nuts\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ab47508f175d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T04:43:09.409999Z",
     "start_time": "2025-09-11T04:43:09.061204Z"
    },
    "id": "559ab47508f175d4"
   },
   "outputs": [],
   "source": [
    "fig = plot_pdgrm(idata=gw150914_psd_patricio, interactive=True)\n",
    "display(HTML(fig.to_html(include_plotlyjs=\"cdn\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca3826635c70021",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T04:36:49.286156Z",
     "start_time": "2025-09-11T04:36:03.823007Z"
    },
    "id": "5ca3826635c70021"
   },
   "outputs": [],
   "source": [
    "gw150914_psd = run_mcmc(\n",
    "    pdgrm,\n",
    "    n_warmup=1000,\n",
    "    n_samples=2000,\n",
    "    knot_kwargs=dict(degree=3, method=\"lvk\"),\n",
    "    verbose=True,\n",
    "    sampler=\"nuts\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631804faffad9394",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T04:37:59.629641Z",
     "start_time": "2025-09-11T04:37:59.305332Z"
    },
    "id": "631804faffad9394"
   },
   "outputs": [],
   "source": [
    "fig = plot_pdgrm(idata=gw150914_psd, interactive=True)\n",
    "display(HTML(fig.to_html(include_plotlyjs=\"cdn\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e08c1095d63379",
   "metadata": {
    "id": "1e08c1095d63379"
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "### NEW KNOT ALLOCATION SCHEME - TEST ###\n",
    "#########################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# from scipy.signal.windows import gaussian\n",
    "from scipy.stats import beta\n",
    "\n",
    "\n",
    "def extract_peaks(vec):\n",
    "    \"\"\"\n",
    "    vec: array-like, the periodogram in original scale\n",
    "    returns: array with log-peaks, otherwise 0\n",
    "    \"\"\"\n",
    "    vec = np.asarray(vec)\n",
    "    n = len(vec)\n",
    "\n",
    "    # Rolling median (window size 9, centered)\n",
    "    med_psd = (\n",
    "        pd.Series(vec)\n",
    "        .rolling(window=9, center=True, min_periods=1)\n",
    "        .median()\n",
    "        .to_numpy()\n",
    "    )\n",
    "\n",
    "    # Power ratio\n",
    "    ratio_med = vec / (med_psd + np.finfo(float).eps)\n",
    "    log_ratio_med = np.log(ratio_med)\n",
    "\n",
    "    # Replace NaNs with mean\n",
    "    mean_lr = np.nanmean(log_ratio_med)\n",
    "    log_ratio_med = np.where(np.isnan(log_ratio_med), mean_lr, log_ratio_med)\n",
    "\n",
    "    # Threshold = Q3 + 1.5 * (Q3 - Q1)\n",
    "    Q1 = np.nanquantile(log_ratio_med, 0.25)\n",
    "    Q3 = np.nanquantile(log_ratio_med, 0.75)\n",
    "    threshold = Q3 + 1.5 * (Q3 - Q1)\n",
    "\n",
    "    # Find values greater than threshold\n",
    "    out = np.zeros(n)\n",
    "    out[log_ratio_med > threshold] = log_ratio_med[log_ratio_med > threshold]\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def smooth_peaks(vec, d):\n",
    "    \"\"\"\n",
    "    Returns the smoothed vector with peaks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vec : array-like, Vector with peaks.\n",
    "    d : int, Propagation distance to the left and right.\n",
    "    \"\"\"\n",
    "    vec = np.asarray(vec)\n",
    "    out = vec.copy()\n",
    "    n = len(vec)\n",
    "\n",
    "    # Gaussian decay (like gsignal::gausswin in R)\n",
    "    # gauss_win = gaussian(2 * d, std=2.5)\n",
    "    # dec = gauss_win[:d][::-1]  # take first d and reverse\n",
    "\n",
    "    # Beta decay\n",
    "    dec = beta.cdf(np.linspace(0, 1, d + 2)[1:-1], a=2, b=0.5)[::-1]  # Reverse\n",
    "\n",
    "    for i in range(1, d + 1):\n",
    "        # propagate to the left\n",
    "        aux1 = np.concatenate([vec[i:], np.zeros(i)])\n",
    "        # propagate to the right\n",
    "        aux2 = np.concatenate([np.zeros(i), vec[: n - i]])\n",
    "\n",
    "        # apply Gaussian decay\n",
    "        aux1 = aux1 * dec[i - 1]\n",
    "        aux2 = aux2 * dec[i - 1]\n",
    "\n",
    "        # update with maximum\n",
    "        out = np.maximum(out, aux1)\n",
    "        out = np.maximum(out, aux2)\n",
    "\n",
    "    # Areas between peaks: aassign\n",
    "    m0 = np.sum(out) * 0.05  # 5 percent of total peaks\n",
    "    n0 = np.count_nonzero(out)  # number of non-zeros\n",
    "    if n0 > 0:\n",
    "        min_value = m0 / n0\n",
    "        out[out <= min_value] = min_value\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def knotLoc(vec, k, degree, freq=None, eqSpaced=False):\n",
    "    \"\"\"\n",
    "    vec    : numeric array containing the smoothed peaks\n",
    "    k      : number of B-spline densities\n",
    "    degree : positive integer specifying the degree of the B-spline densities\n",
    "    freq   : optional array of corresponding frequencies\n",
    "    eqSpaced : if True, returns equidistant knots\n",
    "    \"\"\"\n",
    "\n",
    "    K = k - degree + 1  # number of internal knots [0,1]\n",
    "\n",
    "    if eqSpaced:\n",
    "        knots = np.linspace(0, 1, K)  # Equidistant knots\n",
    "        return knots\n",
    "\n",
    "    N = len(vec)\n",
    "    dens = vec / np.sum(vec)\n",
    "    cumf = np.cumsum(dens)\n",
    "\n",
    "    if freq is None:\n",
    "        freq1 = 0\n",
    "        freqN = 1\n",
    "    else:\n",
    "        freq1 = freq[0]\n",
    "        freqN = freq[-1]\n",
    "\n",
    "    freq = np.linspace(freq1, freqN, N)\n",
    "\n",
    "    # Distribution function\n",
    "    df = interp1d(freq, cumf, bounds_error=False, fill_value=(0, 1))\n",
    "\n",
    "    # Inverse distribution function\n",
    "    dfvec = df(freq)\n",
    "    invDf = interp1d(dfvec, freq, bounds_error=False, fill_value=\"extrapolate\")\n",
    "\n",
    "    v = np.linspace(0, 1, K)\n",
    "    v = v[1:-1]  # remove first and last\n",
    "\n",
    "    knots = np.concatenate(([freq1], invDf(v), [freqN]))\n",
    "\n",
    "    return knots\n",
    "\n",
    "\n",
    "def grid(g, k):\n",
    "    \"\"\"\n",
    "    Matches the knots (k) to the closest values in the grid (g)\n",
    "    and returns a unique set of knots.\n",
    "\n",
    "    g : array-like, grid of values\n",
    "    k : array-like, knots\n",
    "    \"\"\"\n",
    "    g = np.array(g)\n",
    "    k = np.array(k)\n",
    "\n",
    "    # Find the closest value in g for each knot\n",
    "    out = np.array([g[np.argmin(np.abs(g - v))] for v in k])\n",
    "\n",
    "    # Keep only unique values\n",
    "    out = np.unique(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "print(np.min(freqs))\n",
    "print(np.max(freqs))\n",
    "plt.plot()\n",
    "\n",
    "\n",
    "### TESTING THE CODE ###\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "freqs = lvk_pdgrm.freqs\n",
    "pdgrm = lvk_pdgrm.power\n",
    "\n",
    "# freqs = pdgrm.freqs\n",
    "# pdgrm = pdgrm.power\n",
    "\n",
    "# 1. Identifying peaks\n",
    "aux = extract_peaks(pdgrm)\n",
    "\n",
    "# 2. Smoothed peaks\n",
    "r = smooth_peaks(aux, 40)\n",
    "\n",
    "# 3. Plot identified peaks\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(freqs, aux, linestyle=\"-\", color=\"blue\")\n",
    "plt.title(\"Identified Peaks\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"log Peaks\")\n",
    "plt.show()\n",
    "\n",
    "# 4. Plot areas to allocate knots (smoothed peaks)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(freqs, r, linestyle=\"-\", color=\"red\")\n",
    "plt.title(\"Smoothed peaks\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Smoothed Peaks\")\n",
    "plt.show()\n",
    "\n",
    "#####################\n",
    "### Ploting Knots ###\n",
    "#####################\n",
    "\n",
    "# 1. Compute knots\n",
    "k = knotLoc(vec=r, k=100, freq=freqs, degree=3)\n",
    "k = grid(freqs, k)\n",
    "maxFreq = np.max(freqs)  # Maximum frequency\n",
    "\n",
    "# 2. Plot LVK periodogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(freqs, np.log(pdgrm), linestyle=\"-\", color=\"lightgray\")\n",
    "plt.title(\"LVK Periodogram\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Log-periodogram\")\n",
    "\n",
    "# Red points: knot locations\n",
    "plt.scatter(k, np.full_like(k, -35), color=\"red\", label=\"Knots\")\n",
    "\n",
    "# 3. Distribution function from smoothed peaks\n",
    "N = len(r)\n",
    "dens = r / np.sum(r)\n",
    "cumf = np.cumsum(dens)\n",
    "\n",
    "# Interpolation function (distribution function)\n",
    "df = interp1d(\n",
    "    np.linspace(0, 1, N),\n",
    "    cumf,\n",
    "    kind=\"linear\",\n",
    "    bounds_error=False,\n",
    "    fill_value=(0, 1),\n",
    ")\n",
    "\n",
    "# 4. Plot areas to allocate knots\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(\n",
    "    freqs,\n",
    "    r / np.max(r),\n",
    "    linestyle=\"-\",\n",
    "    color=\"lightgray\",\n",
    "    label=\"Normalized Smoothed Peaks\",\n",
    ")\n",
    "\n",
    "# Add cumulative distribution (red line)\n",
    "plt.plot(freqs, df(np.array(freqs) / 2048), color=\"red\", label=\"CDF\")\n",
    "\n",
    "plt.title(\"Smoothed peaks & CDF\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Normalized Peaks / CDF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
